# -*- coding: utf-8 -*-
import time
import asyncio
import traceback
from rich.console import Group
from rich.markdown import Markdown
from rich.markup import escape
from rich.padding import Padding
from rich.text import Text
from textual.widgets import RichLog, Static, Markdown as MarkdownWidget
from langchain_core.messages import AIMessage, ToolMessage

import qoze_code_agent
from .tui_constants import SPINNER_FRAMES


class TUIStreamOutput:
    """æµå¼è¾“å‡ºé€‚é…å™¨"""

    def __init__(self, main_log: RichLog, stream_display: MarkdownWidget, tool_status: Static):
        self.main_log = main_log
        self.stream_display = stream_display
        self.tool_status = tool_status
        self.tool_start_time = None
        self.tool_timer = None
        self.active_tools = {}
        self.current_display_tool = None
        self.last_update_time = 0

    @staticmethod
    def _get_tool_display_name(tool_name: str, tool_args: dict) -> str:
        display_name = tool_name
        if tool_name == "execute_command":
            cmd = tool_args.get("command", "")
            if cmd:
                short_cmd = cmd[:120] + ("..." if len(cmd) > 120 else "")
                display_name = f"command: {short_cmd}"
        return display_name

    def _update_tool_spinner(self):
        if not self.tool_start_time or not self.current_display_tool:
            return
        elapsed = time.time() - self.tool_start_time
        frame = SPINNER_FRAMES[int(elapsed * 10) % len(SPINNER_FRAMES)]
        m, s = divmod(int(elapsed), 60)
        content = f"[dim bold cyan] {frame} {escape(self.current_display_tool)} {m:02d}:{s:02d}[/]"
        self.tool_status.update(Text.from_markup(content))

    def flush_to_log(self, text: str, reasoning: str):
        if reasoning:
            reasoning_clean = reasoning.strip()
            # æ”¹è¿›æ–¹æ¡ˆï¼šä½¿ç”¨çº¯æ–‡æœ¬ Header + ç¼©è¿›æ ·å¼ï¼Œå»é™¤ Panel è¾¹æ¡†
            # header = Text("Thinking", style="bold cyan")
            # self.main_log.write(header)
            
            # ä½¿ç”¨ç°è‰²æ–œä½“ï¼Œå·¦ç¼©è¿›2ä¸ªå­—ç¬¦
            content = Text(reasoning_clean, style="italic #909090")
            self.main_log.write(Padding(content, (0, 0, 1, 2)))
            
            # æˆ–è€…å¦‚æœæ›´å–œæ¬¢ Markdown å¼•ç”¨æ ·å¼ï¼ˆå¸¦å·¦ä¾§ç«–çº¿ï¼‰ï¼š
            # lines = reasoning_clean.split('\n')
            # md_text = "> ğŸ§  **Thinking Process**\n>\n" + "\n".join([f"> *{line}*" for line in lines])
            # self.main_log.write(Markdown(md_text))
            # self.main_log.write(Text("")) # Spacer

        if text:
            self.main_log.write(Markdown(text))

        self.main_log.scroll_end(animate=False)
        self.stream_display.update("")
        self.stream_display.styles.display = "none"

    async def stream_response(self, current_state, conversation_state, thread_id="default_session"):
        current_response_text = ""
        current_reasoning_content = ""
        total_response_text = ""
        total_reasoning_content = ""
        accumulated_ai_message = None

        self.stream_display.styles.display = "block"
        self.last_update_time = 0

        try:
            async for message_chunk, metadata in qoze_code_agent.agent.astream(
                    current_state,
                    stream_mode="messages",
                    config={"recursion_limit": 300, "configurable": {"thread_id": thread_id}}
            ):
                # self.main_log.write(message_chunk)
                try:
                    current_task = asyncio.current_task()
                    if current_task and current_task.cancelled():
                        raise asyncio.CancelledError("Stream cancelled by user")
                except asyncio.CancelledError:
                    raise
                except Exception:
                    pass

                if isinstance(message_chunk, AIMessage):
                    # FIX: Ensure content is not None to prevent concatenation errors
                    if message_chunk.content is None:
                        message_chunk.content = ""
                    if accumulated_ai_message is None:
                        accumulated_ai_message = message_chunk
                    else:
                        accumulated_ai_message += message_chunk

                if isinstance(message_chunk, ToolMessage):
                    # Flush pending text before showing tool result
                    if current_response_text or current_reasoning_content:
                        self.flush_to_log(current_response_text, current_reasoning_content)
                        current_response_text = ""
                        current_reasoning_content = ""

                    tool_name = self.active_tools.pop(message_chunk.tool_call_id, None)
                    if not tool_name and self.active_tools:
                        # Fallback logic to find corresponding tool
                        if len(self.active_tools) == 1:
                            _id, _name = list(self.active_tools.items())[0]
                            tool_name = _name
                            self.active_tools.clear()
                        else:
                            _id, _name = list(self.active_tools.items())[-1]
                            tool_name = _name
                            del self.active_tools[_id]

                    if not tool_name:
                        tool_name = message_chunk.name if hasattr(message_chunk, "name") else None
                    if not tool_name:
                        tool_name = self.current_display_tool if self.current_display_tool else "Tool"

                    accumulated_ai_message = None

                    if not self.active_tools:
                        if self.tool_timer:
                            self.tool_timer.stop()
                            self.tool_timer = None
                        self.tool_status.update("")
                        self.tool_status.styles.display = "none"
                        self.current_display_tool = None

                    elapsed = time.time() - (self.tool_start_time or time.time())
                    if not self.active_tools:
                        self.tool_start_time = None

                    content_str = str(message_chunk.content)
                    is_error = content_str.startswith("[RUN_FAILED]") or "âŒ" in content_str
                    status_icon = "âœ—" if is_error else "âœ“"
                    color = "red" if is_error else "cyan"
                    icon_color = "red" if is_error else "green"
                    final_msg = f"  [dim bold {icon_color}]{status_icon}[/][dim bold {color}] {escape(tool_name)} in {elapsed:.2f}s[/]"
                    self.main_log.write(Text.from_markup(final_msg))
                    continue

                if accumulated_ai_message and accumulated_ai_message.tool_calls:
                    if current_response_text or current_reasoning_content:
                        self.flush_to_log(current_response_text, current_reasoning_content)
                        current_response_text = ""
                        current_reasoning_content = ""

                    for tool_call in accumulated_ai_message.tool_calls:
                        t_name = tool_call.get("name", "Unknown Tool")
                        t_id = tool_call.get("id", "unknown_id")
                        t_args = tool_call.get("args", {})
                        display_name = self._get_tool_display_name(t_name, t_args)
                        self.active_tools[t_id] = display_name
                        self.current_display_tool = display_name

                        if not self.tool_timer:
                            self.tool_start_time = time.time()
                            self.tool_status.styles.display = "block"
                            self.tool_timer = self.tool_status.set_interval(0.1, self._update_tool_spinner)
                    self.stream_display.styles.display = "block"

                reasoning = ""
                if hasattr(message_chunk, "additional_kwargs") and message_chunk.additional_kwargs:
                    reasoning = message_chunk.additional_kwargs.get("reasoning_content", "")
                if isinstance(message_chunk.content, list):
                    for content_item in message_chunk.content:
                        if isinstance(content_item, dict) and content_item.get("type") == "reasoning_content":
                            rc = content_item.get("reasoning_content", {})
                            reasoning += rc.get("text", "") if isinstance(rc, dict) else str(rc)
                        if isinstance(content_item, dict) and content_item.get("type") == "thinking":
                            reasoning += content_item.get("thinking", "")

                if reasoning:
                    current_reasoning_content += reasoning
                    total_reasoning_content += reasoning

                content = message_chunk.content
                chunk_text = ""
                if isinstance(content, str):
                    chunk_text = content
                elif isinstance(content, list):
                    for item in content:
                        if isinstance(item, dict) and item.get("type") == "text":
                            chunk_text += item.get("text", "")

                if chunk_text:
                    current_response_text += chunk_text
                    total_response_text += chunk_text

                if current_reasoning_content or current_response_text:
                    now = time.time()
                    if now - self.last_update_time > 0.1:
                        md_content = ""
                        if current_reasoning_content:
                            # ä¼˜åŒ–æµå¼è¾“å‡ºæ—¶çš„æ€è€ƒå±•ç¤ºï¼Œä½¿ç”¨ blockquote æ ·å¼
                            # ç”±äº Markdown widget æ›´æ–°æ˜¯å…¨é‡çš„ï¼Œæˆ‘ä»¬éœ€è¦æ„é€ å®Œæ•´çš„ markdown
                            md_content += f"> Thinking Process.....\n>\n"
                            # å°†æ¯ä¸€è¡Œéƒ½åŠ ä¸Šå¼•ç”¨ç¬¦å·ï¼Œç¡®ä¿æ ·å¼ç»Ÿä¸€
                            reasoning_lines = current_reasoning_content.split('\n')
                            md_content += "\n".join([f"> *{line}*" for line in reasoning_lines])
                            md_content += "\n\n---\n\n"

                        if current_response_text:
                            md_content += current_response_text

                        try:
                            current_task = asyncio.current_task()
                            if current_task and current_task.cancelled():
                                break
                        except Exception:
                            pass

                        await self.stream_display.update(md_content)
                        self.main_log.scroll_end(animate=False)
                        self.stream_display.scroll_end(animate=False)
                        self.last_update_time = now

            self.flush_to_log(current_response_text, current_reasoning_content)

        # State is managed by MemorySaver

        except asyncio.CancelledError:
            self.stream_display.styles.display = "none"
            raise
        except Exception as e:
            traceback.print_exc()
            error_msg = str(e)
            if "429" in error_msg or "overloaded" in error_msg.lower():
                suggestion = "âš ï¸ æœåŠ¡ç«¯è´Ÿè½½è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•æˆ–åˆ‡æ¢å…¶ä»–æ¨¡å‹ã€‚"
            else:
                suggestion = ""
            self.main_log.write(Text(f"Stream Error: {e}{suggestion}", style="red"))
            self.stream_display.styles.display = "none"
        finally:
            if total_response_text or total_reasoning_content:
                conversation_state["llm_calls"] += 1
            if self.tool_timer:
                self.tool_timer.stop()
                self.tool_timer = None
            self.tool_status.update("")
            self.tool_status.styles.display = "none"
            self.active_tools.clear()
            self.current_display_tool = None
            self.tool_start_time = None
            self.last_update_time = 0
